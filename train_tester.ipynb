{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from monodepthloss import MonodepthLoss\n",
    "from depthencoder import depthencoder \n",
    "from depth_decoder import *\n",
    "DEVICE = torch.device(\"cuda:0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('disp', 3) is torch.Size([4, 1, 80, 32])\n",
      "('disp', 2) is torch.Size([4, 1, 160, 64])\n",
      "('disp', 1) is torch.Size([4, 1, 320, 128])\n",
      "('disp', 0) is torch.Size([4, 1, 640, 256])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4, 3,640,256).to(DEVICE)\n",
    "encoderdecoder = DepthDecoder().to(DEVICE)\n",
    "xout = encoderdecoder(x.view(-1,3,640,256))\n",
    "for key in xout.keys():\n",
    "    print(f\"{key} is {xout[key].size()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import movieparser\n",
    "import time\n",
    "from torchvision.utils import save_image\n",
    "import torchvision\n",
    "\n",
    "optimizer = optim.Adam(encoderdecoder.parameters(),lr=0.001)\n",
    "\n",
    "# network.load_state_dict(torch.load('model2.t'))\n",
    "\n",
    "training_data = np.load(\"numpy_img/skyscraper_lowres-1.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 6970/10000 [12:54<05:23,  9.38it/s]"
     ]
    }
   ],
   "source": [
    "testing = False\n",
    "results = []\n",
    "j = 0\n",
    "mean = []\n",
    "f= open(f\"logs/results-{int(time.time())}.txt\",\"w+\")\n",
    "epochs = 1\n",
    "#loss_function = MonodepthLoss(n=4, SSIM_w=0.85,\\\n",
    "#                disp_gradient_w=0.1, lr_w=1).to(DEVICE)\n",
    "loss_function = MonodepthLoss(n=4, SSIM_w=0.85,\\\n",
    "                disp_gradient_w=0.1, lr_w=1).to(DEVICE)\n",
    "for epoch in range(epochs):\n",
    "    samps = list(range(len(training_data)))\n",
    "    random.shuffle(samps)\n",
    "    for frame in tqdm(samps):\n",
    "        LinNimg = torch.from_numpy(training_data[4999:5000,0]).type(torch.cuda.FloatTensor)\n",
    "        RoutNimg = torch.from_numpy(training_data[4999:5000,1]).type(torch.cuda.FloatTensor)\n",
    "        # LinNm, LinN, LinNp, RoutNm, RoutN, RoutNp = movieparser.getframeset(frameset, images)\n",
    "        LinN = torch.div(LinNimg, 255).permute(0,3,1,2)\n",
    "        RoutN = torch.div(RoutNimg, 255).permute(0,3,1,2)\n",
    "\n",
    "        \n",
    "        encoderdecoder.zero_grad()\n",
    "\n",
    "        output1 = encoderdecoder(LinN.view(-1,3,256,640))\n",
    "        output2 = encoderdecoder(RoutN.view(-1,3,256,640))\n",
    "        '''output1 = encoderdecoder(torch.cat([LinNm.type(torch.cuda.FloatTensor), \\\n",
    "                         LinN.type(torch.cuda.FloatTensor), \\\n",
    "                         LinNp.type(torch.cuda.FloatTensor)], 1))\n",
    "        output2 = encoderdecoder(torch.cat([RoutNm.type(torch.cuda.FloatTensor), \\\n",
    "                         RoutN.type(torch.cuda.FloatTensor), \\\n",
    "                         RoutNp.type(torch.cuda.FloatTensor)], 1))'''\n",
    "        if(testing):\n",
    "            plt.imshow(RoutNimg.cpu())\n",
    "            plt.show()\n",
    "            plt.imshow(output1[('disp', 0)][0].view(256, 640).cpu().detach().numpy(), 'gray')\n",
    "            plt.show()\n",
    "            break\n",
    "        output = []\n",
    "        for i in output1.keys():\n",
    "            output.insert(0, torch.cat((output1[i], output2[i]), 1))\n",
    "        loss = loss_function(output,[LinN.view(-1,3,256,640),RoutN.view(-1,3,256,640)])\n",
    "        #criterion = nn.MSELoss()\n",
    "        #loss = criterion(output[-1], torch.cat([LinN[:,0,:,:], \\\n",
    "        #                                        RoutN[:,0,:,:]], 0).view(-1,2,256,640))\n",
    "        \n",
    "        loss.backward()\n",
    "        mean.append(loss.item())\n",
    "        if j % 100 == 0:\n",
    "            f.write(f\"{round(sum(mean)/len(mean),5)}\\n\")\n",
    "            f.flush()\n",
    "            results.append(sum(mean)/len(mean))\n",
    "            mean = []\n",
    "        j += 1\n",
    "        if False:#j % 500000 == 0:\n",
    "            thetime = int(time.time())\n",
    "            torch.save(encoderdecoder.state_dict(), f\"encoderdecoder-{thetime}\")\n",
    "            save_image(RoutN.cpu(), \\\n",
    "                       f'imageout/{thetime}-left.png')\n",
    "            save_image(output1[('disp', 0)][0].cpu(), \\\n",
    "                       f'imageout/{thetime}-depth.png')\n",
    "        optimizer.step()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(output1[('disp', 0)][0].view(256, 640).cpu().detach().numpy(), 'gray')\n",
    "plt.show()\n",
    "plt.imshow(RoutN.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LinN = torch.from_numpy(training_data[3000][0]).type(torch.cuda.FloatTensor)\n",
    "\n",
    "plt.imshow(torch.div(LinN.cpu(),255))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LinNimg = torch.from_numpy(training_data[1:5,0]).type(torch.cuda.FloatTensor)\n",
    "print(f\"before: {LinNimg.size()}\")\n",
    "print(f\"after: {LinNimg.permute(0,3,2,1).size()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LinNimg = torch.from_numpy(training_data[4999:5000,1]).type(torch.cuda.FloatTensor)\n",
    "LinN = torch.add(torch.div(LinNimg, 255),-.5).permute(0,3,1,2)\n",
    "plt.imshow(LinN.view(3,256,640).permute(1,2,0).cpu())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
