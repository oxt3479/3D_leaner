{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import monodepthloss\n",
    "DEVICE = torch.device(\"cuda:0\")\n",
    "# Moving to the gpu: net = Net().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1, 160, 90])\n",
      "torch.Size([3, 1, 320, 180])\n",
      "torch.Size([3, 1, 640, 360])\n",
      "torch.Size([3, 1, 1280, 720])\n"
     ]
    }
   ],
   "source": [
    "class autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder, self).__init__()\n",
    "        encode = []\n",
    "        relu = nn.ReLU(True)\n",
    "        pool = nn.MaxPool2d(2)\n",
    "        encode.append(nn.Sequential(nn.Conv2d(1, 32, 3, padding=1), relu, pool))\n",
    "        encode.append(nn.Sequential(nn.Conv2d(32, 64, 3, padding=1), relu, pool))\n",
    "        encode.append(nn.Sequential(nn.Conv2d(64, 128, 3, padding=1), relu, pool))\n",
    "        encode.append(nn.Sequential(nn.Conv2d(128, 256, 3, padding=1), relu, pool))\n",
    "        encode.append(nn.Sequential(nn.Conv2d(256, 256, 3, padding=1), relu))\n",
    "        \n",
    "        self.encoders = []\n",
    "        self.encoders.append(nn.Sequential(*encode).to(DEVICE)) # for n\n",
    "        self.encoders.append(nn.Sequential(*encode).to(DEVICE)) # for n-1 & n+1\n",
    "        #self.encoders.append(nn.Sequential(*encode).to(DEVICE)) # for D(n-1) & D(n+1)\n",
    "        \n",
    "        decode = []\n",
    "        decode.append(nn.Sequential(nn.Conv2d(256*3, 256, 3, padding = 1), relu))\n",
    "        decode.append(nn.Sequential(nn.ConvTranspose2d(256*4, 128, 3, stride=2, \\\n",
    "                                                       padding=1, output_padding=1), relu))\n",
    "        decode.append(nn.Sequential(nn.ConvTranspose2d(128*4, 64, 3, stride=2, \\\n",
    "                                                       padding=1, output_padding=1), relu))\n",
    "        decode.append(nn.Sequential(nn.ConvTranspose2d(64*4, 32, 3, stride=2, \\\n",
    "                                                       padding=1, output_padding=1), relu))\n",
    "        decode.append(nn.Sequential(nn.ConvTranspose2d(32*4, 1, 3, stride=2, \\\n",
    "                                                       padding=1, output_padding=1), relu))\n",
    "        self.decoder = nn.Sequential(*decode).to(DEVICE)\n",
    "        todepth = []\n",
    "        todepth.append(nn.Sequential(nn.Conv2d(128, 1, 3, padding = 1), relu).to(DEVICE))\n",
    "        todepth.append(nn.Sequential(nn.Conv2d(64, 1, 3, padding = 1), relu).to(DEVICE))\n",
    "        todepth.append(nn.Sequential(nn.Conv2d(32, 1, 3, padding = 1), relu).to(DEVICE))\n",
    "        self.todepth = todepth # Layers to convert intermediate results into maps\n",
    "\n",
    "\n",
    "        '''\n",
    "        transform = []\n",
    "        transform.append(nn.Sequential(nn.Conv3d(1, 32, 3), relu))\n",
    "        transform.append(nn.Sequential(nn.Conv2d(32, 1, 3), relu))\n",
    "        \n",
    "        self.transformer = nn.Sequential(*transform)\n",
    "        '''    \n",
    "    def forward(self, x1, x2, x3):\n",
    "        xout = []\n",
    "        inputs = [x1,x2,x3]\n",
    "        skips = [[],[],[]]\n",
    "        for i in range(3):\n",
    "            x = inputs[i]\n",
    "            for layer in self.encoders[i-1]: #Encoder 2 used for n-1 and n+1 (x1,x3)\n",
    "                x = layer(x)\n",
    "                skips[i].append(x)\n",
    "        x = skips[-1][-1]\n",
    "        for i, layer in enumerate(self.decoder):\n",
    "            for j, encoder in enumerate(skips):\n",
    "                if j == len(skips)-1 and i == 0: break\n",
    "                x = torch.cat((x,encoder[-(i+1)]),1)\n",
    "            x = layer(x)\n",
    "            if(i > 0):\n",
    "                if(i == 4):\n",
    "                    xout.append(x)\n",
    "                else:\n",
    "                    xout.append(self.todepth[i-1](x))\n",
    "        skips = []\n",
    "        return xout\n",
    "\n",
    "network = autoencoder()\n",
    "network = network.to(DEVICE)\n",
    "x = torch.randn(3,1280,720).to(DEVICE)\n",
    "xout = network(x.view(-1,1,1280,720),x.view(-1,1,1280,720),x.view(-1,1,1280,720))\n",
    "for tensor in xout:\n",
    "    print(tensor.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 87000/135212 [9:00:46<27:15:44,  2.04s/it]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "images = os.listdir('left/skyscraper')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "'''\n",
    "#SOURCE: MONODEPTH 1    \n",
    "def apply_disparity(img, disp):\n",
    "    batch_size, _, height, width = img.size()\n",
    "\n",
    "    # Original coordinates of pixels\n",
    "    x_base = torch.linspace(0, 1, width).repeat(batch_size,\n",
    "                height, 1).type_as(img)\n",
    "    y_base = torch.linspace(0, 1, height).repeat(batch_size,\n",
    "                width, 1).transpose(1, 2).type_as(img)\n",
    "\n",
    "    # Apply shift in X direction\n",
    "    x_shifts = disp[:, 0, :, :]  # Disparity is passed in NCHW format with 1 channel\n",
    "    flow_field = torch.stack((x_base + x_shifts, y_base), dim=3)\n",
    "    # In grid_sample coordinates are assumed to be between -1 and 1\n",
    "    output = F.grid_sample(img, 2*flow_field - 1, mode='bilinear',\n",
    "                           padding_mode='zeros')\n",
    "\n",
    "    return output'''\n",
    "\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(network.parameters(),lr=0.01) # .parameters() takes the parts \n",
    "    # that can be optimized, ie\n",
    "    # they have not been pretrained and frozen.\n",
    "    # lr or learning rate might decay over time in more complicated situations, .001 is common e-3\n",
    "    # We wont be decaying it here however!\n",
    "frames = list(range(len(images)))\n",
    "frames = frames[1200:-10900] # Remove meaningless title images.\n",
    "EPOCHS = 1\n",
    "testing = False\n",
    "i = 0\n",
    "results = []\n",
    "#network.load_state_dict(torch.load('model2.t'))\n",
    "for epoch in range(EPOCHS):\n",
    "    random.shuffle(frames)\n",
    "    for frame in tqdm(frames):\n",
    "        imageLNm = cv2.imread('left/skyscraper/'+images[frame-2], cv2.IMREAD_GRAYSCALE)\n",
    "        imageLN = cv2.imread('left/skyscraper/'+images[frame-1], cv2.IMREAD_GRAYSCALE)\n",
    "        imageLNp = cv2.imread('left/skyscraper/'+images[frame], cv2.IMREAD_GRAYSCALE)\n",
    "        LinNm = torch.as_tensor(imageLNm,dtype=float).view(-1,1,1280,720).to(DEVICE)\n",
    "        LinN = torch.as_tensor(imageLN,dtype=float).view(-1,1,1280,720).to(DEVICE)\n",
    "        LinNp = torch.as_tensor(imageLNp,dtype=float).view(-1,1,1280,720).to(DEVICE)\n",
    "        LinNm = torch.div(LinNm, 255)\n",
    "        LinN = torch.div(LinN, 255)\n",
    "        LinNp = torch.div(LinNp, 255)\n",
    "        \n",
    "        imageRNm = cv2.imread('right/skyscraper/'+images[frame-2][0:-4]+'_R.jpg', \\\n",
    "                              cv2.IMREAD_GRAYSCALE)\n",
    "        imageRN = cv2.imread('right/skyscraper/'+images[frame-1][0:-4]+'_R.jpg', \\\n",
    "                             cv2.IMREAD_GRAYSCALE)\n",
    "        imageRNp = cv2.imread('right/skyscraper/'+images[frame][0:-4]+'_R.jpg', \\\n",
    "                              cv2.IMREAD_GRAYSCALE)\n",
    "        RoutNm = torch.as_tensor(imageRNm,dtype=float).view(-1,1,1280,720).to(DEVICE)\n",
    "        RoutN = torch.as_tensor(imageRN,dtype=float).view(-1,1,1280,720).to(DEVICE)\n",
    "        RoutNp = torch.as_tensor(imageRNp,dtype=float).view(-1,1,1280,720).to(DEVICE)\n",
    "        RoutNm = torch.div(RoutNm, 255)\n",
    "        RoutN = torch.div(RoutN, 255)\n",
    "        RoutNp = torch.div(RoutNp, 255)\n",
    "        \n",
    "        network.zero_grad()\n",
    "        output1 = network(LinNm.type(torch.cuda.FloatTensor), \\\n",
    "                         LinN.type(torch.cuda.FloatTensor), \\\n",
    "                         LinNp.type(torch.cuda.FloatTensor))\n",
    "        output2 = network(RoutNm.type(torch.cuda.FloatTensor), \\\n",
    "                         RoutN.type(torch.cuda.FloatTensor), \\\n",
    "                         RoutNp.type(torch.cuda.FloatTensor))\n",
    "        \n",
    "        #reconstructed = apply_disparity(LinN.type(torch.cuda.FloatTensor), output)\n",
    "        if(testing):\n",
    "            plt.imshow(Rout.cpu().view(720, 1280), 'gray')\n",
    "            plt.show()\n",
    "            plt.imshow(output1[-1].view(720, 1280).cpu().detach().numpy(), 'gray')\n",
    "            plt.show()\n",
    "            break\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input [disp1, disp2, disp3, disp4]\n",
    "            target [left, right]\n",
    "        Return:\n",
    "            (float): The loss\n",
    "        \"\"\"\n",
    "        loss_function = monodepthloss.MonodepthLoss(\n",
    "                n=4,\n",
    "                SSIM_w=0.85,\n",
    "                disp_gradient_w=0.1, lr_w=1).to(DEVICE)\n",
    "        output = []\n",
    "        for i in range(len(output1)):\n",
    "            output.append(torch.cat((output1[i], output2[i]), 1))\n",
    "        loss = loss_function(output,[LinN.type(torch.cuda.FloatTensor),\\\n",
    "                                     RoutN.type(torch.cuda.FloatTensor)])\n",
    "        loss.backward()\n",
    "        if (i%100 == 0):\n",
    "            results.append(loss.item())\n",
    "        i +=1\n",
    "        if (i%10000 == 0):\n",
    "            torch.save(network.state_dict(), 'model2.t')\n",
    "        optimizer.step()\n",
    "results.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
